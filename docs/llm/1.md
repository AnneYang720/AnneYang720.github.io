# 第一章：引言
## 1.1 什么是语言模型
语言模型（LM）的经典定义是一种对令牌序列(token)的概率分布。假设我们有一个令牌集的词汇表 $V$ 。语言模型p为每个令牌<span style="color:red">序列</span> $x_{1},...,x_{L}$ ∈ $V$ 分配一个概率（介于0和1之间的数字）：

$$
p(x_1, \dots, x_L)
$$

语言模型也可以做生成任务。如定义所示，语言模型p接受一个序列并返回一个概率来评估其好坏。我们也可以根据语言模型生成一个序列。最纯粹的方法是从语言模型$p$中以概率$p(x_{1:L})$进行采样，表示为：


$$
x_{1:L}∼p.
$$

### 自回归语言模型(Autoregressive language models)
将序列  $x_{1:L}$  的联合分布  $p(x_{1:L})$  的常见写法是使用概率的链式法则：

$$
p(x_{1:L}) = p(x_1) p(x_2 \mid x_1) p(x_3 \mid x_1, x_2) \cdots p(x_L \mid x_{1:L-1}) = \prod_{i=1}^L p(x_i \mid x_{1:i-1}).
$$

特别地，我们需要理解  $p(x_{i}∣x_{1:i−1})$  是一个给定前面的记号  $x_{1:i−1}$ 后，下一个记号  $x_{i}$  的条件概率分布。自回归语言模型的特点是它可以利用例如前馈神经网络等方法有效计算出每个条件概率分布  $p(x_{i}∣x_{1:i−1})$  。在自回归语言模型  $p$  中生成整个序列 $x_{1:L}$ ，我们需要一次生成一个令牌(token)，该令牌基于之前以生成的令牌进行计算获得：

$$
\begin{aligned}
\text { for } i & =1, \ldots, L: \\
x_i & \sim p\left(x_i \mid x_{1: i-1}\right)^{1 / T},
\end{aligned}
$$

其中  $T≥0$  是一个控制我们希望从语言模型中得到多少随机性的温度参数：
- T=0：确定性地在每个位置 i 选择最可能的令牌 $x_{i}$
- T=1：从纯语言模型“正常（normally）”采样
- T=∞：从整个词汇表上的均匀分布中采样

然而，如果我们仅将概率提高到  $1/T$  的次方，概率分布可能不会加和到 1。我们可以通过重新标准化分布来解决这个问题。我们将标准化版本  $p_{T}(x_{i}∣x_{1:i−1})∝p(x_{i}∣x_{1:i−1})^{1/T}$ 称为退火条件概率分布。

具体来说，这个温度参数会应用于每一步的条件概率分布 $p(x_{i}∣x_{1:i−1})$ ，将其幂变为  $1/T$ 。这意味着当  $T$  值较高时，我们会获得更平均的概率分布，生成的结果更具随机性；反之，当 $T$ 值较低时，模型会更倾向于生成概率较高的令牌。

> [!NOTE]  
> 对于每一步的条件概率分布应用温度参数$T$并进行迭代采样，不等同于（除非 $T=1$ ）从整个长度为 L 的序列的"退火"分布中一次性采样

对于非自回归的条件生成，更一般地，我们可以通过指定某个前缀序列 $x_{1:i}$ （称为提示）并采样其余的  $x_{i+1:L}$ （称为补全）来进行条件生成。例如，生成 $T=0$ 的产生的：

$$
\underbrace{{the}, {mouse}, {ate}}_\text{prompt} \stackrel{T=0}{\leadsto} \underbrace{{the}, {cheese}}_\text{completion}.
$$

如果将温度改为 $T=1$ ，可以得到更多的多样性。

### 总结
- 语言模型是序列  $x_{1:L}$ 的概率分布 p
- 直观上，一个好的语言模型应具有语言能力和世界知识
- 自回归语言模型允许有效地生成给定提示 $x_{1:i}$ 的补全 $x_{i+1:L}$
- 温度可以用来控制生成中的变异量

## 1.2 大模型相关历史回顾

### 1.2.1 信息理论、英语的熵、n-gram模型
用于度量概率分布的熵（Entropy）的概念：

$$
H(p) = \sum_x p(x) \log \frac{1}{p(x)}.
$$

熵实际上是一个衡量将样本$x∼p$ 编码（即压缩）成比特串所需要的预期比特数的度量。熵的值越小，表明序列的结构性越强，编码的长度就越短。直观地理解， $\log \frac{1}{p(x)}$  可以视为用于表示出现概率为 $p(x)$ 的元素 $x$ 的编码的长度。

例如，如果 $p(x)=1/8$ ，我们就需要分配  $log_{2}(8)=3$ 个比特（或等价地，$log(8)=2.08$ 个自然单位）。


#### 1.2.1.1 英语的熵
想象存在一个“真实”的分布p，它能产生英语文本样本x∼p。

交叉熵：

$$
H(p, q)=-\sum_x p(x) \log q(x)
$$

这测量了需要多少比特（nats）来编码样本x∼p，使用由模型q给出的压缩方案（用长度为1/q(x)的代码表示x）。

通过语言模型估计熵。一个关键的属性是，交叉熵H(p,q)上界是熵H(p)：

$$
H(p,q) = \sum_x p(x) \log \frac{1}{q(x)}.
$$

这意味着我们可以通过构建一个只有来自真实数据分布$p$的样本的（语言）模型$q$来估计$H(p,q)$，而$H(p)$通常无法访问，如果$p$是英语的话。

所以我们可以通过构建更好的模型q来得到熵H(p)的更好的估计，由H(p,q)衡量。


#### 1.2.1.2 用于下游应用的N-gram模型
N-gram模型。在一个n-gram模型中，关于$x_{i}$的预测只依赖于最后的 $n-1$ 个字符 $x_{i−(n−1):i−1}$ ，而不是整个历史：

$$
p(x_i \mid x_{1:i-1}) = p(x_i \mid x_{i-(n-1):i-1}).
$$

例如，一个trigram（n=3）模型会定义：

$$
p(𝖼𝗁𝖾𝖾𝗌𝖾∣𝗍𝗁𝖾,𝗆𝗈𝗎𝗌𝖾,𝖺𝗍𝖾,𝗍𝗁𝖾)=p(𝖼𝗁𝖾𝖾𝗌𝖾∣𝖺𝗍𝖾,𝗍𝗁𝖾)。
$$

这些概率是基于各种n-gram（例如，𝖺𝗍𝖾 𝗍𝗁𝖾 𝗆𝗈𝗎𝗌𝖾和𝖺𝗍𝖾 𝗍𝗁𝖾 𝖼𝗁𝖾𝖾𝗌𝖾）在大量文本中出现的次数计算的，并且适当地平滑以避免过拟合（例如，Kneser-Ney平滑）。

语言模型被限制在如语音识别和机器翻译等任务中，其中声音信号或源文本提供了足够的信息，只捕获局部依赖关系（而无法捕获长距离依赖关系）并不是一个大问题。

#### 1.2.1.3 神经语言模型
语言模型的一个重要进步是神经网络的引入。[Bengio等人](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)在2003年首次提出了神经语言模型，其中 $p(x_{i}∣x_{i−(n−1):i−1})$ 由神经网络给出：

$$
p(cheese∣ate,the)=some-neural-network(ate,the,cheese)。
$$

注意，上下文长度仍然受到n的限制，但现在对更大的n值估计神经语言模型在统计上是可行的。主要的挑战是训练神经网络在计算上要昂贵得多。

自2003年以来，神经语言建模的两个关键发展包括：
- **Recurrent Neural Networks**（RNNs），包括长短期记忆（LSTMs），使得一个令牌$x_{i}$的条件分布可以依赖于整个上下文 $x_{1:i−1}$ （有效地使 $n=∞$ ），但这些模型难以训练。
- **Transformers**是一个较新的架构（于2017年为机器翻译开发），再次返回固定上下文长度n，但更易于训练（并利用了GPU的并行性）。此外，n可以对许多应用程序“足够大”（GPT-3使用的是n=2048）。

### 总结
- 语言模型最初是在信息理论的背景下研究的，可以用来估计英语的熵
- N-gram模型在计算上极其高效，但在统计上效率低下
- N-gram模型在短上下文长度中与另一个模型（用于语音识别的声学模型或用于机器翻译的翻译模型）联合使用是有用的
- 神经语言模型在统计上是高效的，但在计算上是低效的
- 随着时间的推移，训练大型神经网络已经变得足够可行，神经语言模型已经成为主导的模型范式

## 1.3 这门课的意义
### 1.3.1 能力
迄2018年为止，语言模型主要作为较大系统的组成部分使用（例如语音识别或机器翻译），但如今语言模型越来越具备作为独立系统的能力。

回顾一下，语言模型具备条件生成的能力：在给定提示的情况下生成完成的文本：
$$prompt⇝completion$$

**与监督学习的关系**：在正常的监督学习中，我们指定了一组输入-输出对的数据集，并训练一个模型（例如通过梯度下降的神经网络）以拟合这些示例。每次训练运行都会产生一个不同的模型。然而，通过上下文学习，只有一个语言模型可以通过提示来完成各种不同的任务。上下文学习显然超出了研究人员预期的可能性，是新出现行为的一个例子。


### 1.3.4 总结
- 单一的大型语言模型是一个万事通（也是一无所长）。它可以执行广泛的任务，并且能够具备上下文学习等新出现的行为
- 它们在现实世界中得到广泛部署
- 大型语言模型仍然存在许多重要的风险，这些风险是开放的研究问题
- 成本是广泛获取的一大障碍