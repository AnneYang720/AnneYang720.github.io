{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            line-height: 1.6;\n",
    "            color: #333;\n",
    "        }\n",
    "        h1 {\n",
    "            color: #2F4F4F;\n",
    "        }\n",
    "        h2 {\n",
    "            color: #4682B4;\n",
    "        }\n",
    "        p {\n",
    "            margin: 10px 0;\n",
    "        }\n",
    "        .key-points, .open-questions {\n",
    "            background-color: #F0F8FF;\n",
    "            padding: 15px;\n",
    "            border-left: 5px solid #4682B4;\n",
    "            margin-bottom: 20px;\n",
    "        }\n",
    "        .key-points ul, .open-questions ul {\n",
    "            margin: 0;\n",
    "            padding-left: 20px;\n",
    "        }\n",
    "        .highlight {\n",
    "            color: #B22222;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "          div {\n",
    "            margin: 10px 0;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<h1 style=\"color: #2F4F4F;\">1. Summary of the Approach</h1>\n",
    "<p>In this notebook, I tackled the ARC challenge by framing it as a sequence-to-sequence (seq2seq) translation task, similar to translating from English to French. Here, the input grids and output grids are treated as sequences that need to be translated from one form to another. This approach leverages the power of transformer architectures, which have proven highly effective in language translation tasks.</p>\n",
    "\n",
    "<div class=\"key-points\">\n",
    "    <h2 style=\"color: #4682B4;\">Key Points of the Approach:</h2>\n",
    "    <ul>\n",
    "        <li><span class=\"highlight\">Data Preparation:</span> The input and output grids are pre-processed to ensure consistent dimensions. The grids are padded to a fixed size (30x30), and various augmentations such as rotation are applied to diversify the training data.</li>\n",
    "        <li><span class=\"highlight\">Custom Transformer Model:</span> The model consists of separate encoder and decoder layers, designed to handle categorical data. Each grid cell is represented as a category, and the model uses <code>nn.Embedding</code> layers to convert these categorical values into dense embeddings. Additionally, positional encodings are added to represent the 2D spatial positions of grid cells.</li>\n",
    "        <li><span class=\"highlight\">Start and End Tokens:</span> To help the model understand the beginning and end of sequences, I introduced special tokens (<code>&lt;START&gt;</code> and <code>&lt;END&gt;</code>), similar to techniques used in NLP tasks.</li>\n",
    "        <li><span class=\"highlight\">Training:</span> The model is trained with a relatively high dropout rate of 0.4, which helps in regularization and prevents overfitting. Surprisingly, the model shows promising results during training, effectively learning to translate input grids to output grids.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<h1 style=\"color: #2F4F4F;\">2. Issue with Inference</h1>\n",
    "<p>While the training phase of the model shows great promise with effective learning and generalization, the inference phase does not perform as expected. This discrepancy might stem from the way the transformer model is implemented for this grid-based problem. Although I initially treated the task as a sequence-to-sequence translation problem, similar to language translation, this approach may not be the most suitable for handling 2D grid transformations. The specific requirements and nuances of grid-based reasoning might require a different architecture or handling mechanism that I haven't fully determined yet.</p>\n",
    "\n",
    "<div style=\"background-color: #F0F8FF; padding: 15px; border-left: 5px solid #4682B4; margin-bottom: 20px;\">\n",
    "    <h2 style=\"color: #4682B4;\">Key Points to Consider:</h2>\n",
    "    <ul>\n",
    "        <li><span style=\"color: #B22222; font-weight: bold;\">Possible Misalignment with Grid-Based Problem:</span> The current model might not correctly capture the spatial relationships and transformations required for grid tasks. The way positional encodings and embeddings are applied during inference might not fully align with the structure of grid data.</li>\n",
    "        <li><span style=\"color: #B22222; font-weight: bold;\">Reconsideration of Inference Approach:</span> Unlike typical transformer tasks, starting inference with a <code>&lt;START&gt;</code> token may not be the best strategy for grid-based tasks. An alternative approach could involve a one-shot inference technique, where the model predicts the entire grid output in one go, rather than sequentially. However, the exact implementation of such an approach remains unclear.</li>\n",
    "        <li><span style=\"color: #B22222; font-weight: bold;\">Potential Use of Patches as in Vision Transformers:</span> Another idea could be to treat parts of the grid as patches, similar to the Vision Transformer (ViT) approach, and process them in parallel to capture spatial dependencies more effectively. This would require a redesign of the model architecture to handle grid patches.</li>\n",
    "        <li><span style=\"color: #B22222; font-weight: bold;\">Inconsistent Performance Between Training and Inference:</span> It's puzzling that the model performs so well during training but fails to generalize effectively during inference. This inconsistency could indicate an issue with overfitting to the training data, or it might suggest that the model hasn't fully learned the underlying spatial patterns required for unseen data.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "<h1 style=\"color: #2F4F4F;\">3. Reflection: Not the Path to AGI, but a Step Towards It</h1>\n",
    "<p>While this approach is not the definitive way to achieve Artificial General Intelligence (AGI), it is a small but meaningful step towards exploring how transformers and other deep learning techniques can be applied to grid-based reasoning tasks. The process of framing a grid transformation task as a sequence-to-sequence problem allows us to harness the strengths of transformers while identifying their limitations in such domains.</p>\n",
    "\n",
    "<p>Through this work, I aim to contribute to the broader discussion on the versatility of transformers and their applicability beyond traditional NLP tasks. The challenges faced here also underscore the need for more specialized architectures that can handle grid-based and spatial reasoning tasks more effectively.</p>\n",
    "\n",
    "<div class=\"open-questions\">\n",
    "    <h2>Open Questions:</h2>\n",
    "    <ul>\n",
    "        <li>Why does the model excel during training with a relatively high dropout rate of 0.4, but struggles significantly during inference? Is this due to overfitting to the training data, or is there a fundamental flaw in how the model processes grid data during inference?</li>\n",
    "    </ul>\n",
    "    <p>I'm eager to hear thoughts from the community on what might be going wrong and suggestions on the right approach to solve grid-based problems using transformer architectures.</p>\n",
    "</div>\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:44:37.94212Z",
     "iopub.status.busy": "2024-09-01T08:44:37.941667Z",
     "iopub.status.idle": "2024-09-01T08:44:41.528913Z",
     "shell.execute_reply": "2024-09-01T08:44:41.527737Z",
     "shell.execute_reply.started": "2024-09-01T08:44:37.94209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from termcolor import colored\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "KAGGLE = False\n",
    "DEBUG = False\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "IGNORE_CLASS = 0\n",
    "START_TOKEN = NUM_CLASSES   # 10\n",
    "END_TOKEN = NUM_CLASSES + 1 # 11\n",
    "SEP_TOKEN = NUM_CLASSES + 2 # 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:45:41.940448Z",
     "iopub.status.busy": "2024-09-01T08:45:41.939785Z",
     "iopub.status.idle": "2024-09-01T08:45:41.948518Z",
     "shell.execute_reply": "2024-09-01T08:45:41.947629Z",
     "shell.execute_reply.started": "2024-09-01T08:45:41.940413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set seed for PyTorch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# If using CUDA\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)  # if you are using multi-GPU.\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set seed for Python's built-in random library\n",
    "random.seed(42)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:45:45.862559Z",
     "iopub.status.busy": "2024-09-01T08:45:45.861914Z",
     "iopub.status.idle": "2024-09-01T08:45:45.868703Z",
     "shell.execute_reply": "2024-09-01T08:45:45.867747Z",
     "shell.execute_reply.started": "2024-09-01T08:45:45.862526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def log_message(message: str, color: str = \"black\"):\n",
    "    if DEBUG:\n",
    "        print(colored(message, color))\n",
    "\n",
    "\n",
    "def log_with_condition(message: str, condition=False, color: str = \"blue\"):\n",
    "    if condition:\n",
    "        print(colored(message, color))\n",
    "\n",
    "\n",
    "def log_important(message: str, color: str = \"blue\"):\n",
    "    print(colored(message, color))\n",
    "\n",
    "\n",
    "def log_error(message: str, color: str = \"red\"):\n",
    "    print(message, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:45:48.202766Z",
     "iopub.status.busy": "2024-09-01T08:45:48.202064Z",
     "iopub.status.idle": "2024-09-01T08:45:48.215224Z",
     "shell.execute_reply": "2024-09-01T08:45:48.214111Z",
     "shell.execute_reply.started": "2024-09-01T08:45:48.202728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "colors = [\n",
    "    [0, 0, 0],\n",
    "    [0, 116, 217],\n",
    "    [255, 65, 54],\n",
    "    [46, 204, 64],\n",
    "    [255, 220, 0],\n",
    "    [170, 170, 170],\n",
    "    [240, 18, 190],\n",
    "    [255, 133, 27],\n",
    "    [127, 219, 255],\n",
    "    [135, 12, 37],\n",
    "]\n",
    "\n",
    "\n",
    "def paint(*matrices):\n",
    "    num_matrices = len(matrices)\n",
    "    fig, axes = plt.subplots(1, num_matrices, figsize=(3 * num_matrices, 2))\n",
    "\n",
    "    if num_matrices == 1:\n",
    "        axes = [axes]  # Ensure axes is a list even for a single subplot\n",
    "\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        matrix[matrix < 0] = 0\n",
    "        matrix[matrix > 9] = 9\n",
    "        try:\n",
    "            # Ensure matrix is a 2D array\n",
    "            m, n = matrix.shape\n",
    "            print(f\"Matrix {i} shape: {m, n}\")\n",
    "            unique_values = np.unique(matrix)\n",
    "            print(f\"Unique values in matrix {i}: {unique_values}\")\n",
    "\n",
    "            # Convert matrix values to corresponding colors, ignoring -1\n",
    "            matrix_colored = np.array(\n",
    "                [\n",
    "                    [\n",
    "                        colors[element] if element != -1 else [255, 255, 255]\n",
    "                        for element in row\n",
    "                    ]\n",
    "                    for row in matrix\n",
    "                ]\n",
    "            )\n",
    "            axes[i].imshow(matrix_colored, interpolation='nearest')\n",
    "            axes[i].set_title(f'({m} x {n})')\n",
    "            axes[i].axis('off')\n",
    "        except Exception as ex:\n",
    "            print(f\"Error processing matrix {i}: {ex}\")\n",
    "            pass\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:45:53.355128Z",
     "iopub.status.busy": "2024-09-01T08:45:53.354775Z",
     "iopub.status.idle": "2024-09-01T08:45:53.362752Z",
     "shell.execute_reply": "2024-09-01T08:45:53.361826Z",
     "shell.execute_reply.started": "2024-09-01T08:45:53.355099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pad_to_dimensions(grid, target_size, ignore_class=IGNORE_CLASS):\n",
    "    h, w = grid.shape[0], grid.shape[1]\n",
    "\n",
    "    # Calculate padding to match target_size\n",
    "    pad_bottom = target_size[0] - h\n",
    "    pad_right = target_size[1] - w\n",
    "\n",
    "    # Pad within the original dimensions with zeros\n",
    "    padded_grid = np.pad(\n",
    "        grid,\n",
    "        ((0, pad_bottom), (0, pad_right)),\n",
    "        mode='constant',\n",
    "        constant_values=IGNORE_CLASS,\n",
    "    )\n",
    "\n",
    "    # Pad the rest to maximum size of 30x30 with ignore_class\n",
    "    max_size = (30, 30)\n",
    "    if padded_grid.shape[0] < max_size[0] or padded_grid.shape[1] < max_size[1]:\n",
    "        pad_bottom = max_size[0] - padded_grid.shape[0]\n",
    "        pad_right = max_size[1] - padded_grid.shape[1]\n",
    "        padded_grid = np.pad(\n",
    "            padded_grid,\n",
    "            ((0, pad_bottom), (0, pad_right)),\n",
    "            mode='constant',\n",
    "            constant_values=ignore_class,\n",
    "        )\n",
    "\n",
    "    return padded_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:45:55.526316Z",
     "iopub.status.busy": "2024-09-01T08:45:55.525964Z",
     "iopub.status.idle": "2024-09-01T08:45:55.533502Z",
     "shell.execute_reply": "2024-09-01T08:45:55.532348Z",
     "shell.execute_reply.started": "2024-09-01T08:45:55.526286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def rotate_grid(grid, angle):\n",
    "    if angle == 0:\n",
    "        return grid\n",
    "    elif angle == 90:\n",
    "        return np.rot90(grid, k=1, axes=(1, 0)).tolist()\n",
    "    elif angle == 180:\n",
    "        return np.rot90(grid, k=2, axes=(1, 0)).tolist()\n",
    "    elif angle == 270:\n",
    "        return np.rot90(grid, k=3, axes=(1, 0)).tolist()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Unsupported rotation angle. Supported angles are 0, 90, and 270 degrees.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:45:58.384025Z",
     "iopub.status.busy": "2024-09-01T08:45:58.383675Z",
     "iopub.status.idle": "2024-09-01T08:45:58.390177Z",
     "shell.execute_reply": "2024-09-01T08:45:58.389258Z",
     "shell.execute_reply.started": "2024-09-01T08:45:58.384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pad_to_final_size(grid, final_size=(30, 30), ignore_class=IGNORE_CLASS):\n",
    "    h, w = grid.shape[0], grid.shape[1]\n",
    "\n",
    "    # Calculate padding to match final_size\n",
    "    pad_bottom = final_size[0] - h\n",
    "    pad_right = final_size[1] - w\n",
    "\n",
    "    # Pad within the original dimensions with zeros\n",
    "    padded_grid = np.pad(\n",
    "        grid,\n",
    "        ((0, pad_bottom), (0, pad_right)),\n",
    "        mode='constant',\n",
    "        constant_values=ignore_class,\n",
    "    )\n",
    "\n",
    "    return padded_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:46:01.421995Z",
     "iopub.status.busy": "2024-09-01T08:46:01.421258Z",
     "iopub.status.idle": "2024-09-01T08:46:01.430271Z",
     "shell.execute_reply": "2024-09-01T08:46:01.42916Z",
     "shell.execute_reply.started": "2024-09-01T08:46:01.421961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def shift_grid(grid, step_right=0, step_down=0):\n",
    "    \"\"\"\n",
    "    Shift the grid right and down by the specified steps, filling new cells with zeros.\n",
    "\n",
    "    Args:\n",
    "    grid (numpy.ndarray): The input grid to be shifted.\n",
    "    step_right (int): The number of columns to shift right.\n",
    "    step_down (int): The number of rows to shift down.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The shifted grid.\n",
    "\n",
    "    Example usage:\n",
    "    grid = np.array([[1, 2, 3,0], [4, 5, 6,0], [7, 8, 9,0],[0, 0, 0,0]])\n",
    "    shifted_grid = shift_grid(grid, step_right=1, step_down=0)\n",
    "    print(shifted_grid)\n",
    "    \"\"\"\n",
    "    h, w = grid.shape\n",
    "    shifted_grid = np.zeros_like(grid)\n",
    "\n",
    "    # Shift right\n",
    "    if step_right > 0:\n",
    "        shifted_grid[:, step_right:] = grid[:, :-step_right]\n",
    "    else:\n",
    "        shifted_grid[:, :] = grid[:, :]\n",
    "\n",
    "    # Shift down\n",
    "    if step_down > 0:\n",
    "        shifted_grid[step_down:, :] = shifted_grid[:-step_down, :]\n",
    "        shifted_grid[:step_down, :] = 0\n",
    "    else:\n",
    "        shifted_grid[:, :] = shifted_grid[:, :]\n",
    "\n",
    "    return shifted_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T09:20:31.317315Z",
     "iopub.status.busy": "2024-09-01T09:20:31.316929Z",
     "iopub.status.idle": "2024-09-01T09:20:31.3284Z",
     "shell.execute_reply": "2024-09-01T09:20:31.327477Z",
     "shell.execute_reply.started": "2024-09-01T09:20:31.317285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def scale_up_grid(grid, scale_factor):\n",
    "    # Scale up a grid by repeating its elements along both axes.\n",
    "    # Repeat elements `scale_factor` times along the row (axis=0) and column (axis=1).\n",
    "    return np.repeat(np.repeat(grid, scale_factor, axis=0), scale_factor, axis=1)\n",
    "\n",
    "\n",
    "def custom_zoom(input_grid, final_size=30):\n",
    "    # Custom zoom function to scale the input grid up to a specified final size.\n",
    "    # The input grid is scaled proportionally to the maximum dimension.\n",
    "\n",
    "    # Determine the largest dimension (width or height) of the input grid.\n",
    "    max_dim = max(input_grid.shape)\n",
    "\n",
    "    # Calculate the scaling factor to ensure the larger dimension fits within the final size.\n",
    "    scale_factor = final_size // max_dim\n",
    "\n",
    "    # Scale up the input grid using the calculated scaling factor.\n",
    "    scaled_input_grid = scale_up_grid(input_grid, scale_factor)\n",
    "\n",
    "    # If the scaled grid does not match the final desired size (30x30 by default),\n",
    "    # pad the grid to match the final size using the `pad_to_final_size` function.\n",
    "    if scaled_input_grid.shape != (final_size, final_size):\n",
    "        scaled_input_grid = pad_to_final_size(scaled_input_grid)\n",
    "\n",
    "    # Return the scaled (and potentially padded) grid.\n",
    "    return scaled_input_grid\n",
    "\n",
    "\n",
    "def downscale_grid(grid, target_size):\n",
    "    # Downscale a grid to a target size by taking the most frequent element (mode)\n",
    "    # in each non-overlapping block of the original grid.\n",
    "\n",
    "    # Determine the original size (height and width) of the input grid.\n",
    "    original_size = grid.shape\n",
    "\n",
    "    # Calculate the scaling factors for both dimensions (width and height).\n",
    "    scale_factor_x = original_size[1] // target_size[1]  # Horizontal scaling factor\n",
    "    scale_factor_y = original_size[0] // target_size[0]  # Vertical scaling factor\n",
    "\n",
    "    # Initialize a new grid with the target size filled with zeros.\n",
    "    downscaled_grid = np.zeros(target_size, dtype=grid.dtype)\n",
    "\n",
    "    # Iterate through each block of the grid to downscale it to the target size.\n",
    "    for i in range(target_size[0]):\n",
    "        for j in range(target_size[1]):\n",
    "            # Extract a block from the original grid that corresponds to the current position.\n",
    "            block = grid[\n",
    "                i * scale_factor_y : (i + 1) * scale_factor_y,\n",
    "                j * scale_factor_x : (j + 1) * scale_factor_x,\n",
    "            ]\n",
    "\n",
    "            # Find the most frequent element (mode) in the current block and assign it to the downscaled grid.\n",
    "            downscaled_grid[i, j] = np.bincount(block.flatten()).argmax()\n",
    "\n",
    "    # Return the downscaled grid.\n",
    "    return downscaled_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T09:20:33.82821Z",
     "iopub.status.busy": "2024-09-01T09:20:33.827833Z",
     "iopub.status.idle": "2024-09-01T09:20:33.843231Z",
     "shell.execute_reply": "2024-09-01T09:20:33.842186Z",
     "shell.execute_reply.started": "2024-09-01T09:20:33.828179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(challenges, task_id_to_index):\n",
    "    input_grids, output_grids, task_idxs = [], [], []\n",
    "    dimensions = {}\n",
    "\n",
    "    for task_id, data in challenges.items():\n",
    "        # task_ids.append(task_id)\n",
    "        task_idx = task_id_to_index[task_id]\n",
    "        dimensions[task_id] = {}\n",
    "        dimensions[task_id]['inputs'] = []\n",
    "        dimensions[task_id]['outputs'] = []\n",
    "        previous_input_dimensions = (0, 0)\n",
    "\n",
    "        ## Rotation\n",
    "        train = [train for train in data['train']]\n",
    "        temp = train.copy()\n",
    "        for t in train:\n",
    "            xinput = t['input']\n",
    "            output = t['output']\n",
    "            for angle in [0, 90, 180, 270]:\n",
    "                temp.append(\n",
    "                    {\n",
    "                        \"input\": rotate_grid(xinput, angle),\n",
    "                        \"output\": rotate_grid(output, angle),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        data['train'] = temp\n",
    "\n",
    "        ## \n",
    "        for sample in data['train']:\n",
    "            input_grid = np.array(sample['input'], dtype=np.int32)\n",
    "            output_grid = np.array(sample['output'], dtype=np.int32)\n",
    "\n",
    "            # Store dimensions in dictionaries\n",
    "            if previous_input_dimensions != input_grid.shape:\n",
    "                dimensions[task_id]['inputs'].append(input_grid.shape)\n",
    "                dimensions[task_id]['outputs'].append(output_grid.shape)\n",
    "                previous_input_dimensions = input_grid.shape\n",
    "\n",
    "            input_grid = custom_zoom(input_grid)\n",
    "            output_grid = custom_zoom(output_grid)\n",
    "\n",
    "            input_grids.append(torch.tensor(input_grid, dtype=torch.long))\n",
    "            output_grids.append(torch.tensor(output_grid, dtype=torch.long))\n",
    "            task_idxs.append(task_idx)\n",
    "\n",
    "    return (torch.stack(input_grids), torch.stack(output_grids), dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:46:21.211476Z",
     "iopub.status.busy": "2024-09-01T08:46:21.210752Z",
     "iopub.status.idle": "2024-09-01T08:46:21.216894Z",
     "shell.execute_reply": "2024-09-01T08:46:21.215933Z",
     "shell.execute_reply.started": "2024-09-01T08:46:21.211439Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(challenges_path, solutions_path):\n",
    "    with open(challenges_path, 'r') as f:\n",
    "        challenges = json.load(f)\n",
    "    with open(solutions_path, 'r') as f:\n",
    "        solutions = json.load(f)\n",
    "    \n",
    "    for task_id in challenges.keys():\n",
    "        solution = solutions[task_id][0]\n",
    "        challenges[task_id]['test'][0]['output'] = solution\n",
    "\n",
    "    return challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Transformer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:46:25.340239Z",
     "iopub.status.busy": "2024-09-01T08:46:25.339853Z",
     "iopub.status.idle": "2024-09-01T08:46:25.355005Z",
     "shell.execute_reply": "2024-09-01T08:46:25.35397Z",
     "shell.execute_reply.started": "2024-09-01T08:46:25.340208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=7200):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = self.generate_encoding(d_model, max_len)\n",
    "        self.inference_encoding = self.generate_inference_encoding(d_model)\n",
    "\n",
    "    def generate_encoding(self, d_model, max_len):\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        encoding = torch.zeros(max_len, d_model)\n",
    "        encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        encoding = encoding.unsqueeze(0)\n",
    "        return encoding\n",
    "\n",
    "    def generate_inference_encoding(self, d_model, height=30, width=30):\n",
    "        num_positions = height * width\n",
    "        position = torch.arange(0, num_positions).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        encoding = torch.zeros(num_positions, d_model)\n",
    "        encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        #         encoding = encoding.view(1, height, width, d_model)  # Reshape for 2D grid\n",
    "        encoding = encoding.unsqueeze(0)\n",
    "\n",
    "        return encoding\n",
    "\n",
    "    def forward(self, x, mode=\"training\"):\n",
    "\n",
    "        log_message(f\"x shape: {x.shape}\")\n",
    "        if x.size(0) > 1:\n",
    "            x = x.reshape(batch_size, -1, 256)\n",
    "        else:\n",
    "            x = x.reshape(1, -1, 256)\n",
    "\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "            print(f\"x unsqueeze shape: {x.shape}\")\n",
    "\n",
    "        try:\n",
    "            x = x + self.encoding[:, : x.size(1), : x.size(2)].to(x.device)\n",
    "        except:\n",
    "            print(f\"x shape: {x.shape}\")\n",
    "            print(f\"x size shape: {x.size}\")\n",
    "            print(\n",
    "                f\"x self.encoding[:, :x.size(1), :x.size(2)] shape: {self.encoding[:, :x.size(1), :x.size(2)].shape}\"\n",
    "            )\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T09:00:28.018628Z",
     "iopub.status.busy": "2024-09-01T09:00:28.018238Z",
     "iopub.status.idle": "2024-09-01T09:00:28.042785Z",
     "shell.execute_reply": "2024-09-01T09:00:28.041724Z",
     "shell.execute_reply.started": "2024-09-01T09:00:28.018597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomTransformerCategorical(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model,\n",
    "        num_categories,\n",
    "        nhead,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        dim_feedforward,\n",
    "        dropout_rate=0.1,\n",
    "    ):\n",
    "        super(CustomTransformerCategorical, self).__init__()\n",
    "        self.num_categories = (\n",
    "            num_categories + 2\n",
    "        )  # Accounting for <start> and <end> tokens\n",
    "        self.grid_embedding = nn.Embedding(\n",
    "            self.num_categories, d_model\n",
    "        )  # Embedding layer for categories\n",
    "        self.grid_positional_encoding = PositionalEncoding(d_model)\n",
    "        self.grid_positional_encoding_inference = PositionalEncoding(\n",
    "            d_model, max_len=30 * 30\n",
    "        )\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=self.d_model,\n",
    "                nhead=nhead,\n",
    "                dim_feedforward=dim_feedforward,\n",
    "                dropout=dropout_rate,\n",
    "            ),\n",
    "            num_layers=num_encoder_layers,\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(\n",
    "                d_model=self.d_model,\n",
    "                nhead=nhead,\n",
    "                dim_feedforward=dim_feedforward,\n",
    "                dropout=dropout_rate,\n",
    "            ),\n",
    "            num_layers=num_decoder_layers,\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(\n",
    "            self.d_model, self.num_categories\n",
    "        )  # Output layer for categories\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = torch.triu(torch.ones(sz, sz), 1).transpose(0, 1)\n",
    "        mask = (\n",
    "            mask.float()\n",
    "            .masked_fill(mask == 1, float('-inf'))\n",
    "            .masked_fill(mask == 0, float(0.0))\n",
    "        )\n",
    "        return mask\n",
    "    \n",
    "    def generate_upper_triangular_mask(self, N, M):\n",
    "        \"\"\"Generate a NxN mask with M tokens already in context window\n",
    "        \"\"\"\n",
    "        mask = torch.zeros(N, N)\n",
    "        mlen = N - M\n",
    "        mask[:mlen, -mlen:] = torch.triu(torch.ones(mlen, mlen), diagonal=0)\n",
    "        mask = (\n",
    "            mask.float()\n",
    "            .masked_fill(mask == 1, float('-inf'))\n",
    "        )\n",
    "        return mask\n",
    "\n",
    "    def forward(self, encoder_input, decoder_in, src_mask=None, tgt_mask=None):\n",
    "        memories = []\n",
    "        for sample in encoder_input:\n",
    "            # Embedding and positional encoding for encoder sequence\n",
    "            encoder_emb = self.grid_embedding(sample)\n",
    "            encoder_emb = self.dropout(encoder_emb)  # Apply dropout after embedding\n",
    "            encoder_emb_pos = self.grid_positional_encoding(encoder_emb)\n",
    "\n",
    "            # Encoder\n",
    "            memory = self.encoder(encoder_emb_pos.transpose(0, 1), src_key_padding_mask=src_mask)\n",
    "            memories.append(memory)\n",
    "        \n",
    "        encoder_mem = torch.mean(torch.stack(memories), dim=0)\n",
    "\n",
    "        # Embedding and positional encoding for output grids\n",
    "        decoder_emb = self.grid_embedding(decoder_in)\n",
    "        decoder_emb = self.dropout(decoder_emb)\n",
    "        decoder_emb_pos = self.grid_positional_encoding(decoder_emb)\n",
    "\n",
    "        # decoder input SEP 及之前的长度\n",
    "        decoder_mem_length = decoder_in.index(SEP_TOKEN) + 1\n",
    "\n",
    "        # tgt_mask 去掉已知（SEP及之前）的长度，其余是一个上三角矩阵\n",
    "        if tgt_mask is None:\n",
    "            tgt_mask = self.generate_upper_triangular_mask(\n",
    "                decoder_emb_pos.size(1), decoder_mem_length\n",
    "            )\n",
    "            print(tgt_mask)\n",
    "\n",
    "        # Decoder\n",
    "        # TODO 这样截取是否正确？\n",
    "        transformer_output = self.decoder(\n",
    "            decoder_emb_pos.transpose(0, 1),\n",
    "            encoder_mem,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=src_mask,\n",
    "        )[decoder_mem_length:]\n",
    "        transformer_output = self.dropout(transformer_output)\n",
    "\n",
    "        # Logits for categories\n",
    "        output = self.fc_out(transformer_output.transpose(0, 1))\n",
    "\n",
    "        return output\n",
    "\n",
    "    # TODO 改写 predict\n",
    "    def predict(self, input_grid):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            input_grid_tensor = (\n",
    "                torch.tensor(input_grid, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "            )\n",
    "            # input_grid_tensor = torch.tensor(input_grid, dtype=torch.long).to(device)\n",
    "\n",
    "            input_emb = self.grid_embedding(input_grid_tensor)\n",
    "            log_message(f\"input_emb.shape: {input_emb.shape} \")\n",
    "            grid_emb = self.grid_positional_encoding(input_emb)\n",
    "            log_message(f\"grid_emb.shape: {grid_emb.shape}\")\n",
    "            memory = self.encoder(grid_emb.transpose(0, 1))\n",
    "            print(f\"memory: {memory}\")\n",
    "\n",
    "            # Initialize the output grid with the <start> token\n",
    "            output_grids = torch.full(\n",
    "                (input_grid_tensor.size(0), 1),\n",
    "                START_TOKEN,\n",
    "                dtype=torch.long,\n",
    "                device=DEVICE,\n",
    "            )\n",
    "\n",
    "            # Decode the output grid\n",
    "            for _ in range(1, grid_emb.size(1)):\n",
    "                output_emb = self.grid_embedding(output_grids)\n",
    "                output_emb = self.grid_positional_encoding_inference(output_emb)\n",
    "                transformer_output = self.decoder(output_emb.transpose(0, 1), memory)\n",
    "                output_logits = self.fc_out(transformer_output.transpose(0, 1))\n",
    "\n",
    "                next_token = torch.argmax(output_logits[:, -1, :], dim=-1, keepdim=True)\n",
    "                output_grids = torch.cat([output_grids, next_token], dim=1)\n",
    "\n",
    "                if next_token.item() == END_TOKEN:\n",
    "                    break\n",
    "\n",
    "            output_grids = output_grids.squeeze().cpu().numpy()\n",
    "\n",
    "            return output_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:46:34.643295Z",
     "iopub.status.busy": "2024-09-01T08:46:34.642653Z",
     "iopub.status.idle": "2024-09-01T08:46:34.648089Z",
     "shell.execute_reply": "2024-09-01T08:46:34.647096Z",
     "shell.execute_reply.started": "2024-09-01T08:46:34.643264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_start_end_tokens(grid):\n",
    "    return [START_TOKEN] + grid + [END_TOKEN]\n",
    "\n",
    "\n",
    "def remove_start_end_tokens(grid):\n",
    "    return grid[1:-1]\n",
    "\n",
    "\n",
    "def add_special_tokens_to_grids(grid1, grid2):\n",
    "    return [START_TOKEN] + grid1 + [SEP_TOKEN] + grid2 + [END_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:46:37.186577Z",
     "iopub.status.busy": "2024-09-01T08:46:37.186194Z",
     "iopub.status.idle": "2024-09-01T08:46:37.193461Z",
     "shell.execute_reply": "2024-09-01T08:46:37.192533Z",
     "shell.execute_reply.started": "2024-09-01T08:46:37.186544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_data_with_tokens(\n",
    "    input_grids, output_grids, start_token=START_TOKEN, end_token=END_TOKEN\n",
    "):\n",
    "    input_grids_with_tokens = []\n",
    "    output_grids_with_tokens = []\n",
    "\n",
    "    for input_grid, output_grid in zip(input_grids, output_grids):\n",
    "        # Flatten the input and output grids\n",
    "        input_grid_flat = input_grid.flatten().tolist()\n",
    "        output_grid_flat = output_grid.flatten().tolist()\n",
    "\n",
    "        # Add start and end tokens\n",
    "        input_grid_with_tokens = add_start_end_tokens(input_grid_flat)\n",
    "        output_grid_with_tokens = add_start_end_tokens(output_grid_flat)\n",
    "\n",
    "        # Convert to tensors\n",
    "        input_grids_with_tokens.append(\n",
    "            torch.tensor(input_grid_with_tokens, dtype=torch.long).to(DEVICE)\n",
    "        )\n",
    "        output_grids_with_tokens.append(\n",
    "            torch.tensor(output_grid_with_tokens, dtype=torch.long).to(DEVICE)\n",
    "        )\n",
    "\n",
    "    return input_grids_with_tokens, output_grids_with_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_encoder_data_with_tokens(input_grids, output_grids):\n",
    "    all_data = []\n",
    "\n",
    "    for input_grid, output_grid in zip(input_grids, output_grids):\n",
    "        # Flatten the input and output grids\n",
    "        input_grid_flat = input_grid.flatten().tolist()\n",
    "        output_grid_flat = output_grid.flatten().tolist()\n",
    "\n",
    "        # Add start and end tokens\n",
    "        tokens = add_special_tokens_to_grids(input_grid_flat, output_grid_flat)\n",
    "\n",
    "        # Convert to tensors\n",
    "        all_data.append(torch.tensor(tokens, dtype=torch.long).to(DEVICE))\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset, model, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for step, data in enumerate(dataset):\n",
    "            # Encoder data\n",
    "            encoder_inputs = [np.array(x['input'], dtype=np.int32) for x in data['train']]\n",
    "            encoder_outputs = [np.array(x['output'], dtype=np.int32) for x in data['train']]\n",
    "\n",
    "            # List[num_samples, seq_length]\n",
    "            encoder_tokens = prepare_encoder_data_with_tokens(\n",
    "                encoder_inputs, encoder_outputs\n",
    "            )\n",
    "\n",
    "            # Decoder data\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # log_message(f\"src shape before embedding: {input_grids_batch.shape}\", \"blue\")\n",
    "\n",
    "            output_logits = model(input_grids_batch, output_grids_batch)\n",
    "            # output_logits = remove_start_end_tokens(output_logits)\n",
    "            if step % 20 == 0:\n",
    "                predictions = torch.argmax(output_logits, dim=-1).cpu().detach().numpy()\n",
    "                actual_outputs = output_grids_batch.cpu().detach().numpy()\n",
    "\n",
    "                paint(\n",
    "                    remove_start_end_tokens(predictions[0]).reshape(30, 30),\n",
    "                    remove_start_end_tokens(actual_outputs[0]).reshape(30, 30),\n",
    "                )\n",
    "\n",
    "            # Compute loss using the logits and true class indices\n",
    "            loss = criterion(\n",
    "                output_logits.view(-1, NUM_CLASSES + 2), output_grids_batch.view(-1)\n",
    "            )  # Flatten to match shapes\n",
    "            # loss = ignore_pad_tokens_loss(output_logits, output_grids_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % 10 == 0:  # Print progress every 10 steps\n",
    "                print(\n",
    "                    f'Epoch [{epoch + 1}/{num_epochs}], Step [{step}/{len(data_loader)}], Loss: {loss.item():.4f}'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T09:20:41.423474Z",
     "iopub.status.busy": "2024-09-01T09:20:41.422799Z",
     "iopub.status.idle": "2024-09-01T09:20:43.081907Z",
     "shell.execute_reply": "2024-09-01T09:20:43.080815Z",
     "shell.execute_reply.started": "2024-09-01T09:20:41.423421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if KAGGLE:\n",
    "    train_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "    train_solutions_path = '/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json'\n",
    "    eval_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json'\n",
    "    eval_solutions_path = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json'\n",
    "    submission_path = '/kaggle/working/submission.json'\n",
    "else:\n",
    "    train_challenges_path = './data/arc-agi_training_challenges.json'\n",
    "    train_solutions_path = './data/arc-agi_training_solutions.json'\n",
    "    eval_challenges_path = './data/arc-agi_evaluation_challenges.json'\n",
    "    eval_solutions_path = './data/arc-agi_evaluation_solutions.json'\n",
    "    submission_path = 'submission.json'\n",
    "\n",
    "train_data = load_data(train_challenges_path, train_solutions_path)\n",
    "val_data = load_data(eval_challenges_path, eval_solutions_path)\n",
    "\n",
    "# train_task_ids = list(challenges.keys())\n",
    "# task_id_to_index = {task_id: idx for idx, task_id in enumerate(train_task_ids)}\n",
    "\n",
    "# input_grids, output_grids, dimensions = prepare_data(challenges, task_id_to_index)\n",
    "\n",
    "# input_grids, output_grids, task_ids = prepare_data(challenges, task_id_to_index)\n",
    "# val_output_grids, val_task_ids_indexes, val_task_ids = prepare_validation_data(solutions, task_id_to_index)\n",
    "\n",
    "num_categories = NUM_CLASSES  # Number of categories (0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T09:20:50.940639Z",
     "iopub.status.busy": "2024-09-01T09:20:50.93984Z",
     "iopub.status.idle": "2024-09-01T09:20:50.954455Z",
     "shell.execute_reply": "2024-09-01T09:20:50.953717Z",
     "shell.execute_reply.started": "2024-09-01T09:20:50.940607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# # Create the dataset\n",
    "# dataset = TensorDataset(input_grids, output_grids)\n",
    "\n",
    "# # Shuffle the dataset before splitting\n",
    "# indices = torch.randperm(len(dataset))\n",
    "\n",
    "# # Split the dataset into training and validation sets (80-20 split)\n",
    "# train_size = int(0.95 * len(indices))\n",
    "# train_indices = indices[:train_size]\n",
    "# val_indices = indices[train_size:]\n",
    "\n",
    "# # Create subsets\n",
    "# train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "# val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "# # Create DataLoaders for training and validation\n",
    "# batch_size = 4\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:46:52.620229Z",
     "iopub.status.busy": "2024-09-01T08:46:52.619879Z",
     "iopub.status.idle": "2024-09-01T08:46:52.62494Z",
     "shell.execute_reply": "2024-09-01T08:46:52.62395Z",
     "shell.execute_reply.started": "2024-09-01T08:46:52.620201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def reset_cuda_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T09:21:15.4084Z",
     "iopub.status.busy": "2024-09-01T09:21:15.407754Z",
     "iopub.status.idle": "2024-09-01T09:21:15.52648Z",
     "shell.execute_reply": "2024-09-01T09:21:15.52552Z",
     "shell.execute_reply.started": "2024-09-01T09:21:15.408368Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the model, loss function, and optimizer\n",
    "num_categories = 10\n",
    "\n",
    "if 'model' in globals():\n",
    "    try:\n",
    "        del model\n",
    "        reset_cuda_memory()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "model = CustomTransformerCategorical(\n",
    "    256,  # Match the embedding dimension\n",
    "    num_categories,\n",
    "    nhead=4,  # 8,6,6\n",
    "    num_encoder_layers=4,\n",
    "    num_decoder_layers=4,\n",
    "    dim_feedforward=2048,\n",
    "    dropout_rate=0.4,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T09:21:17.993883Z",
     "iopub.status.busy": "2024-09-01T09:21:17.993049Z",
     "iopub.status.idle": "2024-09-01T09:21:18.000226Z",
     "shell.execute_reply": "2024-09-01T09:21:17.999232Z",
     "shell.execute_reply.started": "2024-09-01T09:21:17.99384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # For categorical output\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T09:21:19.949745Z",
     "iopub.status.busy": "2024-09-01T09:21:19.949047Z",
     "iopub.status.idle": "2024-09-01T09:26:34.629513Z",
     "shell.execute_reply": "2024-09-01T09:26:34.628554Z",
     "shell.execute_reply.started": "2024-09-01T09:21:19.949714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "train_model(train_data, model, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T08:59:44.869419Z",
     "iopub.status.busy": "2024-09-01T08:59:44.868735Z",
     "iopub.status.idle": "2024-09-01T08:59:44.951286Z",
     "shell.execute_reply": "2024-09-01T08:59:44.950498Z",
     "shell.execute_reply.started": "2024-09-01T08:59:44.869385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/kaggle/working/arc_categorical_avg_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T09:00:39.065103Z",
     "iopub.status.busy": "2024-09-01T09:00:39.064734Z",
     "iopub.status.idle": "2024-09-01T09:00:39.222367Z",
     "shell.execute_reply": "2024-09-01T09:00:39.221487Z",
     "shell.execute_reply.started": "2024-09-01T09:00:39.065074Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "saved_model = CustomTransformerCategorical(\n",
    "    256,  # Match the embedding dimension\n",
    "    num_categories,\n",
    "    nhead=4,  # 8,6,6\n",
    "    num_encoder_layers=4,\n",
    "    num_decoder_layers=4,\n",
    "    dim_feedforward=2048,\n",
    ").to(DEVICE)\n",
    "saved_model.load_state_dict(torch.load('/kaggle/working/arc_categorical_avg_model.pth'))\n",
    "saved_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T09:00:49.720449Z",
     "iopub.status.busy": "2024-09-01T09:00:49.719516Z",
     "iopub.status.idle": "2024-09-01T09:00:54.359047Z",
     "shell.execute_reply": "2024-09-01T09:00:54.357832Z",
     "shell.execute_reply.started": "2024-09-01T09:00:49.72041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def inference(task_id):\n",
    "    test_grid = challenges[task_id]['test'][0]['input']\n",
    "    test_grid = np.array(test_grid, dtype=np.int32)\n",
    "    original_shape = test_grid.shape\n",
    "    test_grid_padded = custom_zoom(test_grid)\n",
    "\n",
    "    paint(test_grid_padded)\n",
    "\n",
    "    t_id = task_id_to_index[task_id]\n",
    "\n",
    "    print(t_id)\n",
    "\n",
    "    test_grid_padded = torch.tensor(test_grid_padded).to(DEVICE)\n",
    "\n",
    "    print(f\"test_grid_padded shape: {test_grid_padded.shape}\")\n",
    "    output = saved_model.predict(test_grid_padded.reshape(1, 30, 30))\n",
    "    return output\n",
    "\n",
    "\n",
    "for i in range(13, 14, 1):\n",
    "    task_id = train_task_ids[i]\n",
    "    t_id = task_id_to_index[task_id]\n",
    "    print(t_id)\n",
    "    output = inference(task_id)\n",
    "    paint(output.reshape(30, 30))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8951125,
     "sourceId": 67357,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
